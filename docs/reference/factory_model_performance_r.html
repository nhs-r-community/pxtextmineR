<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Evaluate the performance of a fitted pipeline — factory_model_performance_r • pxtextmineR</title>


<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous" />

<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script>

<!-- bootstrap-toc -->
<link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>




<meta property="og:title" content="Evaluate the performance of a fitted pipeline — factory_model_performance_r" />
<meta property="og:description" content="Performance metrics on the test set." />




<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->



  </head>

  <body data-spy="scroll" data-target="#toc">
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">pxtextmineR</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.3.2</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/pxtextmineR-vignette.html">pxtextmineR-vignette</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Evaluate the performance of a fitted pipeline</h1>
    
    <div class="hidden name"><code>factory_model_performance_r.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Performance metrics on the test set.</p>
    </div>

    <pre class="usage"><span class='fu'>factory_model_performance_r</span><span class='op'>(</span><span class='va'>pipe</span>, <span class='va'>x_train</span>, <span class='va'>y_train</span>, <span class='va'>x_test</span>, <span class='va'>y_test</span>, <span class='va'>metric</span><span class='op'>)</span></pre>

    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>x_train</th>
      <td><p>Data frame. Training data (predictor).</p></td>
    </tr>
    <tr>
      <th>y_train</th>
      <td><p>Vector. Training data (response).</p></td>
    </tr>
    <tr>
      <th>x_test</th>
      <td><p>Data frame. Test data (predictor).</p></td>
    </tr>
    <tr>
      <th>y_test</th>
      <td><p>Vector. Test data (response).</p></td>
    </tr>
    <tr>
      <th>metric</th>
      <td><p>String. Scorer that was used in pipeline tuning
("accuracy_score", "balanced_accuracy_score", "matthews_corrcoef",
"class_balance_accuracy_score")</p></td>
    </tr>
    </table>

    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>A list of length 5:</p><ul>
<li><p><code>pipe</code> The fitted <code>Scikit-learn</code>/<code>imblearn</code> pipeline.</p></li>
<li><p><code>tuning_results</code> Data frame. All (hyper)parameter values
and models tried during fitting.</p></li>
<li><p><code>pred</code> Vector. The predictions on the test
set.</p></li>
<li><p><code>accuracy_per_class</code> Data frame. Accuracies per class.</p></li>
<li><p><code>p_compare_models_bar</code> A bar plot comparing the mean scores (of
the user-supplied <code>metric</code> parameter) from the cross-validation
on the training set, for the best (hyper)parameter values for
each learner.</p></li>
</ul>

    <h2 class="hasAnchor" id="note"><a class="anchor" href="#note"></a>Note</h2>

    <p>Returned object <code>tuning_results</code> lists all (hyper)parameter values
tried during pipeline fitting, along with performance metrics. It is
generated from the <code>Scikit-learn</code> output that follows pipeline fitting.
It is derived from attribute <a href='https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html'><code>cv_results_</code></a>
with some modifications. In R, <code>cv_results_</code> can be accessed following
fitting of a pipeline with <code><a href='factory_pipeline_r.html'>pxtextmineR::factory_pipeline_r</a></code> or by
calling function <code>pxtextmineR::factory_model_performance_r</code>. Say that
the fitted pipeline is assigned to an object called <code>pipe</code>, and that the
pipeline performance is assigned to an object called <code>pipe_performance</code>.
Then, <code>cv_results_</code> can be accessed with <code>pipe$cv_results_</code> or
<code>pipe_performance$cv_results_</code>. <br /><br />
<strong>NOTE</strong>: After calculating performance metrics on the test set,
<code>pxtextmineR::factory_model_performance_r</code> fits the pipeline on the
<strong>whole</strong> dataset (train + test). Hence, do not be surprised that the
pipeline's <code>score()</code> method will now return a dramatically improved score
on the test set- the refitted pipeline has now "seen" the test dataset
(see Examples). The re-fitted pipeline will perform much better on fresh
data than the pipeline fitted on <code>x_train</code> and <code>y_train</code> only.</p>
    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>Pedregosa F., Varoquaux G., Gramfort A., Michel V., Thirion B., Grisel O.,
Blondel M., Prettenhofer P., Weiss R., Dubourg V., Vanderplas J., Passos A.,
Cournapeau D., Brucher M., Perrot M. &amp; Duchesnay E. (2011),
<a href='https://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html'>Scikit-learn: Machine Learning in Python</a>.
<em>Journal of Machine Learning Research</em> 12:2825–-2830.</p>

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='co'># Prepare training and test sets</span>
<span class='va'>data_splits</span> <span class='op'>&lt;-</span> <span class='fu'>pxtextmineR</span><span class='fu'>::</span><span class='fu'><a href='factory_data_load_and_split_r.html'>factory_data_load_and_split_r</a></span><span class='op'>(</span>
  filename <span class='op'>=</span> <span class='fu'>pxtextmineR</span><span class='fu'>::</span><span class='va'><a href='text_data.html'>text_data</a></span>,
  target <span class='op'>=</span> <span class='st'>"label"</span>,
  predictor <span class='op'>=</span> <span class='st'>"feedback"</span>,
  test_size <span class='op'>=</span> <span class='fl'>0.90</span><span class='op'>)</span> <span class='co'># Make a small training set for a faster run in this example</span>

<span class='co'># Let's take a look at the returned list</span>
<span class='fu'><a href='https://rdrr.io/r/utils/str.html'>str</a></span><span class='op'>(</span><span class='va'>data_splits</span><span class='op'>)</span>
</div><div class='output co'>#&gt; List of 6
#&gt;  $ x_train            :'data.frame':	1033 obs. of  1 variable:
#&gt;   ..$ predictor: chr [1:1033] "Very helpful and friendly." "Prompt appointment - information delivered clearly video appointment but everything worked well.  Tian was very kind. " "FIrst Class" "Be a bit quicker when they are discharging you." ...
#&gt;   ..- attr(*, "pandas.index")=Int64Index([5503, 2371, 3214, 8067, 5880, 5011, 9713, 5085, 1416, 3565,
#&gt;             ...
#&gt;             1879, 3833, 5913,  130, 7556, 1177, 1287, 2813, 8771, 1690],
#&gt;            dtype='int64', length=1033)
#&gt;  $ x_test             :'data.frame':	9301 obs. of  1 variable:
#&gt;   ..$ predictor: chr [1:9301] "Absolutely happy wIth everythIng, very nIce people." "More staff    At times the ward felt understaffed and with such poorly children" "Always lIstened to regardIng any Issues." "Listen.  \nStaff communication with each other was excellent, it gave me a much better experience this time.  T"| __truncated__ ...
#&gt;   ..- attr(*, "pandas.index")=Int64Index([ 2663,  8720,  2772,  1634,  7900,  1815,  2534,  1766, 10026,
#&gt;              7140,
#&gt;             ...
#&gt;              1213,  5090,  1385,  5740,  4183,  7520,  2770,  2408,  5436,
#&gt;              1266],
#&gt;            dtype='int64', length=9301)
#&gt;  $ y_train            : chr [1:1033(1d)] "Care received" "Access" "Care received" "Transition/coordination" ...
#&gt;   ..- attr(*, "dimnames")=List of 1
#&gt;   .. ..$ : chr [1:1033] "5503" "2371" "3214" "8067" ...
#&gt;  $ y_test             : chr [1:9301(1d)] "Care received" "Staff" "Communication" "Communication" ...
#&gt;   ..- attr(*, "dimnames")=List of 1
#&gt;   .. ..$ : chr [1:9301] "2663" "8720" "2772" "1634" ...
#&gt;  $ index_training_data: int [1:1033] 5503 2371 3214 8067 5880 5011 9713 5085 1416 3565 ...
#&gt;  $ index_test_data    : int [1:9301] 2663 8720 2772 1634 7900 1815 2534 1766 10026 7140 ...</div><div class='input'>
<span class='co'># Fit the pipeline</span>
<span class='va'>pipe</span> <span class='op'>&lt;-</span> <span class='fu'>pxtextmineR</span><span class='fu'>::</span><span class='fu'><a href='factory_pipeline_r.html'>factory_pipeline_r</a></span><span class='op'>(</span>
  x <span class='op'>=</span> <span class='va'>data_splits</span><span class='op'>$</span><span class='va'>x_train</span>,
  y <span class='op'>=</span> <span class='va'>data_splits</span><span class='op'>$</span><span class='va'>y_train</span>,
  tknz <span class='op'>=</span> <span class='st'>"spacy"</span>,
  ordinal <span class='op'>=</span> <span class='cn'>FALSE</span>,
  metric <span class='op'>=</span> <span class='st'>"accuracy_score"</span>,
  cv <span class='op'>=</span> <span class='fl'>2</span>, n_iter <span class='op'>=</span> <span class='fl'>10</span>, n_jobs <span class='op'>=</span> <span class='fl'>1</span>, verbose <span class='op'>=</span> <span class='fl'>3</span>,
  learners <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"SGDClassifier"</span>, <span class='st'>"MultinomialNB"</span><span class='op'>)</span>
<span class='op'>)</span>
<span class='co'># (SGDClassifier represents both logistic regression and linear SVM. This</span>
<span class='co'># depends on the value of the "loss" hyperparameter, which can be "log" or</span>
<span class='co'># "hinge". This is set internally in factory_pipeline_r).</span>

<span class='co'># Assess model performance</span>
<span class='va'>pipe_performance</span> <span class='op'>&lt;-</span> <span class='fu'>pxtextmineR</span><span class='fu'>::</span><span class='fu'>factory_model_performance_r</span><span class='op'>(</span>
  pipe <span class='op'>=</span> <span class='va'>pipe</span>,
  x_train <span class='op'>=</span> <span class='va'>data_splits</span><span class='op'>$</span><span class='va'>x_train</span>,
  y_train <span class='op'>=</span> <span class='va'>data_splits</span><span class='op'>$</span><span class='va'>y_train</span>,
  x_test <span class='op'>=</span> <span class='va'>data_splits</span><span class='op'>$</span><span class='va'>x_test</span>,
  y_test <span class='op'>=</span> <span class='va'>data_splits</span><span class='op'>$</span><span class='va'>y_test</span>,
  metric <span class='op'>=</span> <span class='st'>"accuracy_score"</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/base/names.html'>names</a></span><span class='op'>(</span><span class='va'>pipe_performance</span><span class='op'>)</span>
</div><div class='output co'>#&gt; [1] "pipe"                 "tuning_results"       "pred"                
#&gt; [4] "accuracy_per_class"   "p_compare_models_bar"</div><div class='input'>
<span class='co'># Let's compare pipeline performance for different tunings with a range of</span>
<span class='co'># metrics averaging the cross-validation metrics for each fold.</span>
<span class='va'>pipe_performance</span><span class='op'>$</span>
  <span class='va'>tuning_results</span> <span class='op'>%&gt;%</span>
  <span class='fu'>dplyr</span><span class='fu'>::</span><span class='fu'><a href='https://dplyr.tidyverse.org/reference/select.html'>select</a></span><span class='op'>(</span><span class='va'>learner</span>, <span class='fu'>dplyr</span><span class='fu'>::</span><span class='fu'><a href='https://tidyselect.r-lib.org/reference/starts_with.html'>contains</a></span><span class='op'>(</span><span class='st'>"mean_test"</span><span class='op'>)</span><span class='op'>)</span>
</div><div class='output co'>#&gt;         learner mean_test_Accuracy mean_test_Balanced Accuracy
#&gt; 2      Logistic          0.5575941                   0.3137440
#&gt; 0      Logistic          0.5324266                   0.3695176
#&gt; 6 MultinomialNB          0.5217639                   0.3385196
#&gt; 5      Logistic          0.5169227                   0.3449101
#&gt; 4 MultinomialNB          0.4375384                   0.3138912
#&gt; 3    Linear SVM          0.4307424                   0.2475875
#&gt; 1      Logistic          0.4288344                   0.2762078
#&gt; 7    Linear SVM          0.3988275                   0.2486355
#&gt; 8 MultinomialNB          0.3987862                   0.2584215
#&gt; 9 MultinomialNB          0.3678272                   0.2691415
#&gt;   mean_test_Matthews Correlation Coefficient mean_test_Class Balance Accuracy
#&gt; 2                                  0.4173449                        0.2784928
#&gt; 0                                  0.4026087                        0.3276369
#&gt; 6                                  0.3868081                        0.3025500
#&gt; 5                                  0.3850773                        0.3081798
#&gt; 4                                  0.3069311                        0.2523217
#&gt; 3                                  0.2640922                        0.2134373
#&gt; 1                                  0.2682233                        0.2329601
#&gt; 7                                  0.2369170                        0.2099112
#&gt; 8                                  0.2538160                        0.2117422
#&gt; 9                                  0.2251304                        0.1871887</div><div class='input'>
<span class='co'># A glance at the (hyper)parameters and their tuned values</span>
<span class='va'>pipe_performance</span><span class='op'>$</span>
  <span class='va'>tuning_results</span> <span class='op'>%&gt;%</span>
  <span class='fu'>dplyr</span><span class='fu'>::</span><span class='fu'><a href='https://dplyr.tidyverse.org/reference/select.html'>select</a></span><span class='op'>(</span><span class='va'>learner</span>, <span class='fu'>dplyr</span><span class='fu'>::</span><span class='fu'><a href='https://tidyselect.r-lib.org/reference/starts_with.html'>contains</a></span><span class='op'>(</span><span class='st'>"param_"</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'><a href='https://rdrr.io/r/utils/str.html'>str</a></span><span class='op'>(</span><span class='op'>)</span>
</div><div class='output co'>#&gt; 'data.frame':	10 obs. of  22 variables:
#&gt;  $ learner                                                    : chr  "Logistic" "Logistic" "MultinomialNB" "Logistic" ...
#&gt;  $ param_sampling__kw_args                                    : chr  "{'up_balancing_counts': 800}" "{'up_balancing_counts': 300}" "{'up_balancing_counts': 800}" "{'up_balancing_counts': 800}" ...
#&gt;  $ param_preprocessor__texttr__text__transformer__use_idf     :List of 10
#&gt;   ..$ : logi FALSE
#&gt;   ..$ : logi TRUE
#&gt;   ..$ : logi TRUE
#&gt;   ..$ : logi FALSE
#&gt;   ..$ : logi FALSE
#&gt;   ..$ : logi FALSE
#&gt;   ..$ : logi FALSE
#&gt;   ..$ : logi TRUE
#&gt;   ..$ : logi TRUE
#&gt;   ..$ : logi TRUE
#&gt;  $ param_preprocessor__texttr__text__transformer__tokenizer   : chr  "&lt;pxtextmining.helpers.tokenization.LemmaTokenizer object at 0x000000006F3FA730&gt;" "&lt;pxtextmining.helpers.tokenization.LemmaTokenizer object at 0x000000006F3FA730&gt;" "&lt;pxtextmining.helpers.tokenization.LemmaTokenizer object at 0x000000006F3FAC10&gt;" "&lt;pxtextmining.helpers.tokenization.LemmaTokenizer object at 0x000000006F3FA730&gt;" ...
#&gt;  $ param_preprocessor__texttr__text__transformer__preprocessor: chr  "&lt;function text_preprocessor at 0x00000000665D93A0&gt;" "&lt;function text_preprocessor at 0x00000000665D93A0&gt;" "&lt;function text_preprocessor at 0x00000000665D93A0&gt;" "&lt;function text_preprocessor at 0x00000000665D93A0&gt;" ...
#&gt;  $ param_preprocessor__texttr__text__transformer__norm        :List of 10
#&gt;   ..$ : NULL
#&gt;   ..$ : chr "l2"
#&gt;   ..$ : chr "l2"
#&gt;   ..$ : chr "l2"
#&gt;   ..$ : NULL
#&gt;   ..$ : chr "l2"
#&gt;   ..$ : chr "l2"
#&gt;   ..$ : chr "l2"
#&gt;   ..$ : chr "l2"
#&gt;   ..$ : chr "l2"
#&gt;  $ param_preprocessor__texttr__text__transformer__ngram_range : chr  "(1, 3)" "(1, 3)" "(1, 3)" "(1, 3)" ...
#&gt;  $ param_preprocessor__texttr__text__transformer__min_df      :List of 10
#&gt;   ..$ : int 1
#&gt;   ..$ : int 1
#&gt;   ..$ : int 1
#&gt;   ..$ : int 1
#&gt;   ..$ : int 1
#&gt;   ..$ : int 1
#&gt;   ..$ : int 3
#&gt;   ..$ : int 3
#&gt;   ..$ : int 3
#&gt;   ..$ : int 3
#&gt;  $ param_preprocessor__texttr__text__transformer__max_df      :List of 10
#&gt;   ..$ : num 0.7
#&gt;   ..$ : num 0.7
#&gt;   ..$ : num 0.95
#&gt;   ..$ : num 0.95
#&gt;   ..$ : num 0.95
#&gt;   ..$ : num 0.7
#&gt;   ..$ : num 0.7
#&gt;   ..$ : num 0.95
#&gt;   ..$ : num 0.7
#&gt;   ..$ : num 0.7
#&gt;  $ param_preprocessor__texttr__text__transformer              : chr  "TfidfVectorizer(max_df=0.7, ngram_range=(1, 3), norm=None,\n                preprocessor=&lt;function text_preproc"| __truncated__ "TfidfVectorizer(max_df=0.7, ngram_range=(1, 3), norm=None,\n                preprocessor=&lt;function text_preproc"| __truncated__ "TfidfVectorizer()" "TfidfVectorizer(max_df=0.7, ngram_range=(1, 3), norm=None,\n                preprocessor=&lt;function text_preproc"| __truncated__ ...
#&gt;  $ param_preprocessor__sentimenttr__scaler__scaler__n_bins    :List of 10
#&gt;   ..$ : int 8
#&gt;   ..$ : int 4
#&gt;   ..$ : int 8
#&gt;   ..$ : int 8
#&gt;   ..$ : int 4
#&gt;   ..$ : int 4
#&gt;   ..$ : int 8
#&gt;   ..$ : int 8
#&gt;   ..$ : int 8
#&gt;   ..$ : int 4
#&gt;  $ param_preprocessor__sentimenttr__scaler__scaler            : chr  "KBinsDiscretizer(n_bins=8, strategy='kmeans')" "KBinsDiscretizer(n_bins=8, strategy='kmeans')" "KBinsDiscretizer(strategy='kmeans')" "KBinsDiscretizer(n_bins=8, strategy='kmeans')" ...
#&gt;  $ param_preprocessor__lengthtr__scaler__scaler               : chr  "KBinsDiscretizer(n_bins=3, strategy='kmeans')" "KBinsDiscretizer(n_bins=3, strategy='kmeans')" "KBinsDiscretizer(n_bins=3, strategy='kmeans')" "KBinsDiscretizer(n_bins=3, strategy='kmeans')" ...
#&gt;  $ param_featsel__selector__score_func                        : chr  "&lt;function chi2 at 0x00000000665C14C0&gt;" "&lt;function chi2 at 0x00000000665C14C0&gt;" "&lt;function chi2 at 0x00000000665C14C0&gt;" "&lt;function chi2 at 0x00000000665C14C0&gt;" ...
#&gt;  $ param_featsel__selector__percentile                        :List of 10
#&gt;   ..$ : int 70
#&gt;   ..$ : int 100
#&gt;   ..$ : int 85
#&gt;   ..$ : int 70
#&gt;   ..$ : int 70
#&gt;   ..$ : int 100
#&gt;   ..$ : int 85
#&gt;   ..$ : int 100
#&gt;   ..$ : int 70
#&gt;   ..$ : int 85
#&gt;  $ param_featsel__selector                                    : chr  "SelectPercentile(percentile=70,\n                 score_func=&lt;function chi2 at 0x00000000665C14C0&gt;)" "SelectPercentile(percentile=70,\n                 score_func=&lt;function chi2 at 0x00000000665C14C0&gt;)" "SelectPercentile(percentile=70,\n                 score_func=&lt;function chi2 at 0x00000000665C14C0&gt;)" "SelectPercentile(percentile=70,\n                 score_func=&lt;function chi2 at 0x00000000665C14C0&gt;)" ...
#&gt;  $ param_clf__estimator__penalty                              :List of 10
#&gt;   ..$ : chr "l2"
#&gt;   ..$ : chr "elasticnet"
#&gt;   ..$ : num NaN
#&gt;   ..$ : chr "l2"
#&gt;   ..$ : num NaN
#&gt;   ..$ : chr "elasticnet"
#&gt;   ..$ : chr "l2"
#&gt;   ..$ : chr "l2"
#&gt;   ..$ : num NaN
#&gt;   ..$ : num NaN
#&gt;  $ param_clf__estimator__max_iter                             :List of 10
#&gt;   ..$ : int 10000
#&gt;   ..$ : int 10000
#&gt;   ..$ : num NaN
#&gt;   ..$ : int 10000
#&gt;   ..$ : num NaN
#&gt;   ..$ : int 10000
#&gt;   ..$ : int 10000
#&gt;   ..$ : int 10000
#&gt;   ..$ : num NaN
#&gt;   ..$ : num NaN
#&gt;  $ param_clf__estimator__loss                                 :List of 10
#&gt;   ..$ : chr "log"
#&gt;   ..$ : chr "log"
#&gt;   ..$ : num NaN
#&gt;   ..$ : chr "log"
#&gt;   ..$ : num NaN
#&gt;   ..$ : chr "hinge"
#&gt;   ..$ : chr "log"
#&gt;   ..$ : chr "hinge"
#&gt;   ..$ : num NaN
#&gt;   ..$ : num NaN
#&gt;  $ param_clf__estimator__class_weight                         : chr  "None" "None" "nan" "None" ...
#&gt;  $ param_clf__estimator                                       : chr  "SGDClassifier(loss='log', max_iter=10000)" "SGDClassifier(loss='log', max_iter=10000)" "MultinomialNB()" "SGDClassifier(loss='log', max_iter=10000)" ...
#&gt;  $ param_clf__estimator__alpha                                :List of 10
#&gt;   ..$ : num NaN
#&gt;   ..$ : num NaN
#&gt;   ..$ : num 0.1
#&gt;   ..$ : num NaN
#&gt;   ..$ : int 1
#&gt;   ..$ : num NaN
#&gt;   ..$ : num NaN
#&gt;   ..$ : num NaN
#&gt;   ..$ : int 1
#&gt;   ..$ : int 1
#&gt;  - attr(*, "pandas.index")=Int64Index([2, 0, 6, 5, 4, 3, 1, 7, 8, 9], dtype='int64')</div><div class='input'>
<span class='co'># Accuracy per class</span>
<span class='va'>pipe_performance</span><span class='op'>$</span><span class='va'>accuracy_per_class</span>
</div><div class='output co'>#&gt;                     class counts   accuracy
#&gt; 1                  Access    370 0.08648649
#&gt; 2           Care received   3027 0.78328378
#&gt; 3           Communication    786 0.27480916
#&gt; 4    Couldn't be improved   1533 0.89954338
#&gt; 5                 Dignity    128 0.03906250
#&gt; 6 Environment/ facilities    449 0.26057906
#&gt; 7           Miscellaneous    318 0.48427673
#&gt; 8                   Staff   2560 0.59140625
#&gt; 9 Transition/coordination    130 0.08461538</div><div class='input'>
<span class='co'># Learner performance barplot</span>
<span class='va'>pipe_performance</span><span class='op'>$</span><span class='va'>p_compare_models_bar</span>
</div><div class='img'><img src='factory_model_performance_r-1.png' alt='' width='700' height='433' /></div><div class='input'><span class='co'># Remember that we tried three models: Logistic regression (SGDClassifier with</span>
<span class='co'># "log" loss), linear SVM (SGDClassifier with "hinge" loss) and MultinomialNB.</span>
<span class='co'># Do not be surprised if one of these models does not show on the plot.</span>
<span class='co'># There are numerous values for the different (hyper)parameters (recall,</span>
<span class='co'># most of which are set internally) and only `n_iter = 10` iterations in this</span>
<span class='co'># example. As with `factory_pipeline` the choice of which (hyper)parameter</span>
<span class='co'># values to try out is random, one or more classifiers may not be chosen.</span>
<span class='co'># Increasing `n_iter` to a larger number would avoid this, at the expense of</span>
<span class='co'># longer fitting times (but with a possibly more accurate pipeline).</span>

<span class='co'># Predictions on test set</span>
<span class='va'>preds</span> <span class='op'>&lt;-</span> <span class='va'>pipe_performance</span><span class='op'>$</span><span class='va'>pred</span>
<span class='fu'><a href='https://rdrr.io/r/utils/head.html'>head</a></span><span class='op'>(</span><span class='va'>preds</span><span class='op'>)</span>
</div><div class='output co'>#&gt; [1] "Care received"           "Care received"          
#&gt; [3] "Care received"           "Staff"                  
#&gt; [5] "Environment/ facilities" "Care received"          </div><div class='input'>
<span class='co'>################################################################################</span>
<span class='co'># NOTE!!! #</span>
<span class='co'>################################################################################</span>
<span class='co'># After calculating performance metrics on the test set,</span>
<span class='co'># pxtextmineR::factory_model_performance_r fits the pipeline on the WHOLE</span>
<span class='co'># dataset (train + test). Hence, do not be surprised that the pipeline's</span>
<span class='co'># score() method will now return a dramatically improved score on the test</span>
<span class='co'># set- the refitted pipeline has now "seen" the test dataset.</span>
<span class='va'>pipe_performance</span><span class='op'>$</span><span class='va'>pipe</span><span class='op'>$</span><span class='fu'>score</span><span class='op'>(</span><span class='va'>data_splits</span><span class='op'>$</span><span class='va'>x_test</span>, <span class='va'>data_splits</span><span class='op'>$</span><span class='va'>y_test</span><span class='op'>)</span>
</div><div class='output co'>#&gt; [1] 0.9823675</div><div class='input'><span class='va'>pipe</span><span class='op'>$</span><span class='fu'>score</span><span class='op'>(</span><span class='va'>data_splits</span><span class='op'>$</span><span class='va'>x_test</span>, <span class='va'>data_splits</span><span class='op'>$</span><span class='va'>y_test</span><span class='op'>)</span>
</div><div class='output co'>#&gt; [1] 0.9823675</div><div class='input'>
<span class='co'># We can confirm this score by having the re-fitted pipeline predict x_test</span>
<span class='co'># again. The predictions will be better and the new accuracy score will be</span>
<span class='co'># the inflated one.</span>
<span class='va'>preds_refitted</span> <span class='op'>&lt;-</span> <span class='va'>pipe</span><span class='op'>$</span><span class='fu'>predict</span><span class='op'>(</span><span class='va'>data_splits</span><span class='op'>$</span><span class='va'>x_test</span><span class='op'>)</span>

<span class='va'>score_refitted</span> <span class='op'>&lt;-</span> <span class='va'>data_splits</span><span class='op'>$</span><span class='va'>y_test</span> <span class='op'>%&gt;%</span>
  <span class='fu'><a href='https://rdrr.io/r/base/data.frame.html'>data.frame</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>dplyr</span><span class='fu'>::</span><span class='fu'><a href='https://dplyr.tidyverse.org/reference/rename.html'>rename</a></span><span class='op'>(</span>true <span class='op'>=</span> <span class='st'>'.'</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>dplyr</span><span class='fu'>::</span><span class='fu'><a href='https://dplyr.tidyverse.org/reference/mutate.html'>mutate</a></span><span class='op'>(</span>
    pred <span class='op'>=</span> <span class='va'>preds_refitted</span>,
    check <span class='op'>=</span> <span class='va'>true</span> <span class='op'>==</span> <span class='va'>preds_refitted</span>,
    check <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span><span class='op'>(</span><span class='va'>check</span><span class='op'>)</span> <span class='op'>/</span> <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>.</span><span class='op'>)</span>
  <span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>dplyr</span><span class='fu'>::</span><span class='fu'><a href='https://dplyr.tidyverse.org/reference/pull.html'>pull</a></span><span class='op'>(</span><span class='va'>check</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'><a href='https://rdrr.io/r/base/unique.html'>unique</a></span><span class='op'>(</span><span class='op'>)</span>

<span class='va'>score_refitted</span>
</div><div class='output co'>#&gt; [1] 0.9823675</div><div class='input'>
<span class='co'># Compare this to the ACTUAL performance on the test dataset</span>
<span class='va'>preds_actual</span> <span class='op'>&lt;-</span> <span class='va'>pipe_performance</span><span class='op'>$</span><span class='va'>pred</span>

<span class='va'>score_actual</span> <span class='op'>&lt;-</span> <span class='va'>data_splits</span><span class='op'>$</span><span class='va'>y_test</span> <span class='op'>%&gt;%</span>
  <span class='fu'><a href='https://rdrr.io/r/base/data.frame.html'>data.frame</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>dplyr</span><span class='fu'>::</span><span class='fu'><a href='https://dplyr.tidyverse.org/reference/rename.html'>rename</a></span><span class='op'>(</span>true <span class='op'>=</span> <span class='st'>'.'</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>dplyr</span><span class='fu'>::</span><span class='fu'><a href='https://dplyr.tidyverse.org/reference/mutate.html'>mutate</a></span><span class='op'>(</span>
    pred <span class='op'>=</span> <span class='va'>preds_actual</span>,
    check <span class='op'>=</span> <span class='va'>true</span> <span class='op'>==</span> <span class='va'>preds_actual</span>,
    check <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span><span class='op'>(</span><span class='va'>check</span><span class='op'>)</span> <span class='op'>/</span> <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>.</span><span class='op'>)</span>
  <span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>dplyr</span><span class='fu'>::</span><span class='fu'><a href='https://dplyr.tidyverse.org/reference/pull.html'>pull</a></span><span class='op'>(</span><span class='va'>check</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'><a href='https://rdrr.io/r/base/unique.html'>unique</a></span><span class='op'>(</span><span class='op'>)</span>

<span class='va'>score_actual</span>
</div><div class='output co'>#&gt; [1] 0.6234813</div><div class='input'>
<span class='va'>score_refitted</span> <span class='op'>-</span> <span class='va'>score_actual</span>
</div><div class='output co'>#&gt; [1] 0.3588861</div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top">
      <h2 data-toc-skip>Contents</h2>
    </nav>
  </div>
</div>


      <footer>
      <div class="copyright">
  <p>Developed by Andreas D Soteriades.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
   </div>

  


  </body>
</html>


